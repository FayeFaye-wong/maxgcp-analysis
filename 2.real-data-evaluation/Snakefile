"""
Real data analysis.

This analysis compares the sensitivity, specificity, and AUROC of MaxGCP GWAS
versus with naive phenotype GWAS, using real data. To enable this analysis, we
will downsample our cohort of ~350,000 to 20,000, ensuring that even a
maximally powerful phenotyping method will not be powered to detect genetic
associations that would have escaped the full-size naive phenotyping method's
GWAS.

Put differently, compared to the 20,000 sample cohort, the full-size cohort's
GWAS results are so much more powerful that they can reasonably be used as
ground truth, for both positives and negatives. This lets us evaluate MaxGCP
in real data, where gold standards are not available.

General steps:

1. Acquire phenotype data
2. Locate genotype data
3. Create a subsampled cohort (with a pre-defined random seed, in case we need
     to reproduce or repeat the results)
4. Use Haseman-Elston regression to estimate heritability and genetic
     correlation among all phenotypes
5. Build the genetic covariance matrix
6. Build the phenotypic covariance matrix
7. Compute MaxGCP
8. GWAS on naive phenotypes and MaxGCP phenotypes in the reduced dataset
9. GWAS on the naive phenotypes in the full dataset
10. Compare the results
"""

import itertools
import pathlib

import numpy as np
import pandas as pd
import polars as pl

root = pathlib.Path(".")
pheno_path = root.joinpath("../data/pheno/pheno_jan2024.tsv")
covar_path = root.joinpath("../data/pheno/covar.tsv")
geno_path = (
    "/data1/home/mnz2108/data_resources/ukbiobank/hapmap3_genotypes/"
    "hapmap3_variants_white_british"
)

phenotype_names = (
    pl.read_csv(pheno_path, separator="\t", n_rows=0)
    .select("^b_.*$")
    .columns
)
phenotype_idx = [i for i, _ in enumerate(phenotype_names)]
pheno_idx_pairs = list(itertools.combinations(phenotype_idx, 2))


rule all:
  input:
    # Inputs
    pheno_path,
    covar_path,
    # Outputs
    "data/pheno/pheno_sub_0.tsv",
    "data/pheno/covar_sub_0.tsv",
    "data/pheno/samples_sub_0.tsv",
    multiext("data/geno/geno_sub_0", ".bed", ".bim", ".fam"),
    "data/pcov/pcov_sub_0.tsv",


rule subsample_cohort:
  input:
    pheno = pheno_path,
    covar = covar_path,
  output:
    pheno = "data/pheno/pheno_sub_{seed}.tsv",
    covar = "data/pheno/covar_sub_{seed}.tsv",
    samples = "data/pheno/samples_sub_{seed}.tsv",
  run:
    pheno_df = pl.read_csv(input.pheno, separator="\t")
    covar_df = pl.read_csv(input.covar, separator="\t")

    subsampled_pheno_df = pheno_df.sample(n=20_000, with_replacement=False,
                                          seed=int(wildcards.seed))

    subsampled_covar_df = (
        covar_df
        .join(subsampled_pheno_df[["#FID", "IID"]], on=["#FID", "IID"])
    )

    subsampled_pheno_df.write_csv(output.pheno, separator="\t")
    subsampled_covar_df.write_csv(output.covar, separator="\t")
    subsampled_pheno_df[["#FID", "IID"]].write_csv(output.samples, separator="\t")


rule subsample_geno:
  input:
    samples = "data/pheno/samples_sub_{seed}.tsv",
    geno = multiext(geno_path, ".pgen", ".psam", ".pvar"),
  output:
    multiext("data/geno/geno_sub_{seed}", ".bed", ".bim", ".fam"),
  params:
    output_prefix = "data/geno/geno_sub_{seed}",
  shell:
    """
    plink2 --pfile {geno_path} --keep {input.samples} --make-bed \
      --out {params.output_prefix}
    """


rule make_grm:
  input:
    geno = multiext("data/geno/geno_sub_{seed}", ".bed", ".bim", ".fam"),
  output:
    multiext("data/grm/grm_sub_{seed}", ".grm.bin", ".grm.id", ".grm.N.bin"),
  params:
    input_prefix = "data/geno/geno_sub_{seed}",
    output_prefix = "data/grm/grm_sub_{seed}",
  shell:
    """
    gcta --bfile {params.input_prefix} --make-grm --out {params.output_prefix}
    """


rule haseman_elston:
  input:
    phenos = "data/pheno/pheno_sub_{seed}.tsv",
    covar = "data/pheno/covar_sub_{seed}.tsv",
    grm = multiext("data/grm/grm_sub_{seed}.grm", ".bin", ".id", ".N.bin"),
  output:
    "data/rg/rg_sub_{seed}_{i}_{j}.HEreg",
  params:
    grm_prefix = "data/grm/grm_sub_{seed}",
    output_prefix = "data/rg/rg_sub_{seed}_{i}_{j}",
  threads: 1
  shell:
    """
    gcta --HEreg-bivar {wildcards.i} {wildcards.j} --grm {params.grm_prefix} \
      --pheno {input.phenos} --qcovar {input.covar} \
      --out {params.output_prefix}
    """


  input:
    "data/pheno/pheno_sub_{seed}.tsv",
  output:
    "data/pcov/pcov_sub_{seed}.tsv",
  run:
    (
        pl.read_csv(input[0], separator="\t")
        .select("^b_.+$")
        .to_pandas()
        .cov()
        .to_csv(output[0], sep="\t")
    )


rule compute_phenotypic_correlation:
  input:
    pheno = "data/pheno/pheno_sub_{seed}.tsv",
    covar = "../data/pheno/covar.tsv",
  output:
    "data/pcov/pcov_sub_{seed}.tsv",
  run:
    pheno_df = (
        pl.read_csv(input.pheno, separator="\t")
        .select("IID", "^b_.*$")
    )
    covar_df = pl.read_csv(input.covar, separator="\t") .drop("FID")
    merged_df = pheno_df.join(covar_df, on=["IID"])
    Y = merged_df.select(pheno_df.drop("IID").columns).to_numpy()
    X = merged_df.select(covar_df.drop("IID").columns, const=1).to_numpy()
    beta = np.linalg.lstsq(X, Y, rcond=None)[0]
    residuals = Y - X @ beta
    cov = np.cov(residuals, rowvar=False)
    pheno_names = pheno_df.drop("IID").columns
    (
        pd.DataFrame(cov, index=pheno_names, columns=pheno_names)
        .to_csv(output[0], sep="\t")
    )
